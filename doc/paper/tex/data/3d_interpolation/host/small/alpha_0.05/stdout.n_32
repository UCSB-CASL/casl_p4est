Fri Oct 24 17:13:05 CDT 2014
TACC: Starting up job 4334746
TACC: Setting up parallel environment for MVAPICH2+mpispawn.
TACC: Starting parallel tasks...
Petsc version Petsc Release Version 3.4.4, Mar, 13, 2014 
[WARNING]: option 'log_summary' does not exists in the database -- ignoring.
 -------------------== CASL Options Database ==------------------- 
 List of entered options:

  -alpha 0.05
  -lmax 9
  -lmin 0
  -output-dir /scratch/02032/mmirzade/3d_quad_interpolation/reduce/small/alpha_0.05_pre_1/n_32.N_2.4334746
  -prefactor 1
  -qmin 20000000
  -repeat 10
  -test 1
 ----------------------------------------------------------------- 
total time ... 
git commit hash value = 7f54439 (7f54439d82d0f1f2fe8554539839d91d7f283715)
mpisize = 32
connectivity ... 
connectivity ... done in 
 0.00016 secs. on process 0 [Note: only showing root's timings]

brick_size = 1x1x1
p4est generation ... 
p4est generation ... done in 
 0.00022 secs. on process 0 [Note: only showing root's timings]

refine ... 
refine ... done in 
 4.84318 secs. on process 0 [Note: only showing root's timings]

partition ... 
partition ... done in 
 0.00880 secs. on process 0 [Note: only showing root's timings]

ghost ... 
ghost ... done in 
 0.08233 secs. on process 0 [Note: only showing root's timings]

creating node structure ... 
creating node structure ... done in 
 3.07898 secs. on process 0 [Note: only showing root's timings]

gather statistics ... 
% global_quads = 20507957 	 global_nodes = 33282261
% mpi_rank local_node_size local_quad_size ghost_node_size ghost_quad_size
   0, 1016102,  640873, 72007, 20980
   1, 1012568,  640874, 104342, 34734
   2, 1005944,  640873, 65376, 19565
   3, 1012112,  640874, 100283, 32027
   4,  976340,  640874, 96166, 32307
   5, 1032889,  640873, 101586, 36413
   6, 1087256,  640874, 56702, 16663
   7, 1131070,  640874, 140882, 52325
   8, 1094376,  640873, 97174, 33385
   9, 1185221,  640874, 146400, 54260
  10, 1124826,  640874, 64346, 20210
  11, 1108303,  640873, 108057, 41678
  12,  963374,  640874, 96475, 31525
  13, 1026152,  640874, 111497, 40552
  14,  985167,  640873, 85298, 29794
  15, 1096815,  640874, 118173, 46304
  16, 1014162,  640874, 72579, 26614
  17,  992986,  640873, 83940, 29904
  18,  983540,  640874, 75432, 27638
  19,  990710,  640874, 100134, 37479
  20,  986055,  640873, 91099, 32753
  21, 1044073,  640874, 60478, 22625
  22, 1060592,  640874, 99973, 42242
  23, 1065494,  640873, 115995, 43673
  24, 1074897,  640874, 110438, 40373
  25,  945422,  640874, 61448, 23417
  26,  983400,  640873, 40434, 14568
  27,  969338,  640874, 44326, 19525
  28, 1078323,  640874, 101806, 37336
  29, 1073240,  640873, 48312, 18172
  30, 1074448,  640874, 86663, 33991
  31, 1087066,  640874, 48747, 28468
gather statistics ... done in 
 0.00483 secs. on process 0 [Note: only showing root's timings]

hierarchy and node neighbors ... 
hierarchy and node neighbors ... done in 
 1.12624 secs. on process 0 [Note: only showing root's timings]

computing random points ... 
computing random points ... done in 
 0.12582 secs. on process 0 [Note: only showing root's timings]

[0000] interpolation points = 640872 
[0001] interpolation points = 640873 
[0002] interpolation points = 640872 
[0003] interpolation points = 640873 
[0004] interpolation points = 640873 
[0005] interpolation points = 640872 
[0006] interpolation points = 640873 
[0007] interpolation points = 640873 
[0008] interpolation points = 640872 
[0009] interpolation points = 640873 
[0010] interpolation points = 640873 
[0011] interpolation points = 640872 
[0012] interpolation points = 640873 
[0013] interpolation points = 640873 
[0014] interpolation points = 640872 
[0015] interpolation points = 640873 
[0016] interpolation points = 640873 
[0017] interpolation points = 640872 
[0018] interpolation points = 640873 
[0019] interpolation points = 640873 
[0020] interpolation points = 640872 
[0021] interpolation points = 640873 
[0022] interpolation points = 640873 
[0023] interpolation points = 640872 
[0024] interpolation points = 640873 
[0025] interpolation points = 640873 
[0026] interpolation points = 640872 
[0027] interpolation points = 640873 
[0028] interpolation points = 640873 
[0029] interpolation points = 640872 
[0030] interpolation points = 640873 
[0031] interpolation points = 640873 
interpolation test ... 
interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00000 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.35535 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 1.64296 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 1.99872 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00001 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.38461 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 3.21996 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 3.60506 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00001 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.37724 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 5.04275 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 5.42041 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00001 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.34562 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 3.95911 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 4.30514 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00001 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.37801 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 4.47996 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 4.85839 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00000 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.37624 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 3.92705 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 4.30373 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00000 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.36865 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 4.23672 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 4.60578 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00000 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.36629 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 4.42640 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 4.79311 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00000 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.39582 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 3.45854 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 3.85477 secs. on process 0 [Note: only showing root's timings]

interpolation all ... 
constructing interpolation ... 
constructing interpolation ... done in 
 0.00001 secs. on process 0 [Note: only showing root's timings]

adding points ... 
adding points ... done in 
 0.37209 secs. on process 0 [Note: only showing root's timings]

interpolating ... 
interpolating ... done in 
 4.01169 secs. on process 0 [Note: only showing root's timings]

interpolation all ... done in 
 4.38420 secs. on process 0 [Note: only showing root's timings]

interpolation test ... done in 
 42.15641 secs. on process 0 [Note: only showing root's timings]

total time ... done in 
 51.68739 secs. on process 0 [Note: only showing root's timings]

************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

./interpolation_3d on a sandybridge-cxx named c509-302.stampede.tacc.utexas.edu with 32 processors, by mmirzade Fri Oct 24 17:14:08 2014
Using Petsc Release Version 3.4.4, Mar, 13, 2014 

                         Max       Max/Min        Avg      Total 
Time (sec):           5.337e+01      1.00000   5.337e+01
Objects:              7.000e+00      1.00000   7.000e+00
Flops:                0.000e+00      0.00000   0.000e+00  0.000e+00
Flops/sec:            0.000e+00      0.00000   0.000e+00  0.000e+00
MPI Messages:         6.660e+02      2.14839   4.704e+02  1.505e+04
MPI Message Lengths:  1.872e+07      1.67573   3.279e+04  4.935e+08
MPI Reductions:       1.000e+01      1.00000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flops
                            and VecAXPY() for complex vectors of length N --> 8N flops

Summary of Stages:   ----- Time ------  ----- Flops -----  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total   counts   %Total     Avg         %Total   counts   %Total 
 0:      Main Stage: 5.3369e+01 100.0%  0.0000e+00   0.0%  1.505e+04 100.0%  3.279e+04      100.0%  9.000e+00  90.0% 

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flops: Max - maximum over all processors
                   Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   Avg. len: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %f - percent flops in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flops over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flops                             --- Global ---  --- Stage ---   Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   Avg len Reduct  %T %f %M %L %R  %T %f %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

InterpolatingFunctionHost::interpolate                        10 1.0 4.0247e+01 1.1 0.00e+00 0.0 1.3e+04 3.1e+04 0.0e+00 73  0 87 83  0  73  0 87 83  0     0
InterpolatingFunctionHost::process_local                 6088300 1.0 1.5517e+01 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 27  0  0  0  0  27  0  0  0  0     0
InterpolatingFunctionHost::process_queries                   310 2.2 1.4006e+00 2.8 0.00e+00 0.0 6.5e+03 3.1e+04 0.0e+00  2  0 43 42  0   2  0 43 42  0     0
InterpolatingFunctionHost::process_replies               73996763 33.5 1.2706e+01 16.5 0.00e+00 0.0 3.3e+03 2.5e+04 0.0e+00  9  0 22 17  0   9  0 22 17  0     0
InterpolatingFunctionHost::all_reduce                         10 1.0 2.1816e+01 2.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 33  0  0  0  0  33  0  0  0  0     0
my_p4est_hierarchy_t::init                                     1 1.0 9.3733e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
my_p4est_node_neighbors_t::init                                1 1.0 1.2063e+00 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  2  0  0  0  0   2  0  0  0  0     0
my_p4est_nodes_new                                             1 1.0 3.0801e+00 1.0 0.00e+00 0.0 8.7e+02 8.2e+04 1.0e+00  6  0  6 15 10   6  0  6 15 11     0
my_p4est_new                                                   1 1.0 2.6300e-03 17.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
my_p4est_ghost_new                                             1 1.0 8.4064e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
my_p4est_refine                                               65 1.0 4.7450e-01 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
my_p4est_partition                                            66 1.0 1.6231e-01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
log_interpolation_all                                         10 1.0 4.3759e+01 1.1 0.00e+00 0.0 1.3e+04 3.1e+04 0.0e+00 79  0 87 83  0  79  0 87 83  0     0
log_interpolation_add_points                                  10 1.0 3.7199e+00 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  7  0  0  0  0   7  0  0  0  0     0
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Vector     2              2      8707896     0
      Vector Scatter     1              1         1052     0
           Index Set     2              2       289540     0
   IS L to G Mapping     1              1          580     0
              Viewer     1              0            0     0
========================================================================================================================
Average time to get PetscTime(): 1.19209e-07
Average time for MPI_Barrier(): 1.297e-05
Average time for zero size MPI_Send(): 3.2559e-06
#PETSc Option Table entries:
-alpha 0.05
-lmax 9
-lmin 0
-log_summary
-output-dir /scratch/02032/mmirzade/3d_quad_interpolation/reduce/small/alpha_0.05_pre_1/n_32.N_2.4334746
-prefactor 1
-qmin 20000000
-repeat 10
-test 1
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure run at: Sat Apr 26 18:16:46 2014
Configure options: --with-x=0 -with-pic --with-external-packages-dir=/opt/apps/intel13/mvapich2_1_9/petsc/3.4/externalpackages --with-mpi-compilers=1 --with-mpi-dir=/opt/apps/intel13/mvapich2/1.9 --with-clanguage=C++ --with-scalar-type=real --with-dynamic-loading=0 --with-shared-libraries=1 --with-matlab --with-matlab-dir=/work/apps/matlab/2013a --with-spai=1 --download-spai --with-hypre=1 --download-hypre --with-mumps=1 --download-mumps --with-scalapack=1 --download-scalapack --with-blacs=1 --download-blacs --with-spooles=1 --download-spooles --with-superlu=1 --download-superlu --with-superlu_dist=1 --download-superlu_dist --with-parmetis=1 --download-parmetis --with-metis=1 --download-metis --with-hdf5=1 --with-hdf5-dir=/opt/apps/intel13/mvapich2_1_9/phdf5/1.8.9 --with-debugging=no --with-blas-lapack-dir=/opt/apps/intel/13/composer_xe_2013.3.163/mkl/lib/intel64 --with-mpiexec=mpirun_rsh --COPTFLAGS= --CXXOPTFLAGS= --FOPTFLAGS=
-----------------------------------------
Libraries compiled on Sat Apr 26 18:16:46 2014 on build.stampede.tacc.utexas.edu 
Machine characteristics: Linux-2.6.32-358.18.1.el6.x86_64-x86_64-with-centos-6.4-Final
Using PETSc directory: /opt/apps/intel13/mvapich2_1_9/petsc/3.4
Using PETSc arch: sandybridge-cxx
-----------------------------------------

Using C compiler: /opt/apps/intel13/mvapich2/1.9/bin/mpicxx  -wd1572    -fPIC   ${COPTFLAGS} ${CFLAGS}
Using Fortran compiler: /opt/apps/intel13/mvapich2/1.9/bin/mpif90  -fPIC    ${FOPTFLAGS} ${FFLAGS} 
-----------------------------------------

Using include paths: -I/opt/apps/intel13/mvapich2_1_9/petsc/3.4/sandybridge-cxx/include -I/opt/apps/intel13/mvapich2_1_9/petsc/3.4/include -I/opt/apps/intel13/mvapich2_1_9/petsc/3.4/include -I/opt/apps/intel13/mvapich2_1_9/petsc/3.4/sandybridge-cxx/include -I/work/apps/matlab/2013a/extern/include -I/opt/apps/intel13/mvapich2_1_9/phdf5/1.8.9/include -I/opt/apps/intel13/mvapich2/1.9/include
-----------------------------------------

Using C linker: /opt/apps/intel13/mvapich2/1.9/bin/mpicxx
Using Fortran linker: /opt/apps/intel13/mvapich2/1.9/bin/mpif90
Using libraries: -Wl,-rpath,/opt/apps/intel13/mvapich2_1_9/petsc/3.4/sandybridge-cxx/lib -L/opt/apps/intel13/mvapich2_1_9/petsc/3.4/sandybridge-cxx/lib -lpetsc -Wl,-rpath,/opt/apps/intel13/mvapich2_1_9/petsc/3.4/sandybridge-cxx/lib -L/opt/apps/intel13/mvapich2_1_9/petsc/3.4/sandybridge-cxx/lib -lsuperlu_4.3 -lHYPRE -lspai -lsuperlu_dist_3.3 -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -Wl,-rpath,/opt/apps/intel/13/composer_xe_2013.3.163/mkl/lib/intel64 -L/opt/apps/intel/13/composer_xe_2013.3.163/mkl/lib/intel64 -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lpthread -lm -lpthread -lparmetis -lmetis -Wl,-rpath,/opt/apps/intel13/mvapich2_1_9/phdf5/1.8.9/lib -L/opt/apps/intel13/mvapich2_1_9/phdf5/1.8.9/lib -lhdf5_fortran -lhdf5_hl -lhdf5 -Wl,-rpath,/opt/ofed/lib64 -L/opt/ofed/lib64 -Wl,-rpath,/opt/apps/limic2/0.5.5/lib -L/opt/apps/limic2/0.5.5/lib -Wl,-rpath,/opt/apps/intel13/mvapich2/1.9/lib -L/opt/apps/intel13/mvapich2/1.9/lib -Wl,-rpath,/opt/apps/intel/13/composer_xe_2013.3.163/compiler/lib/intel64 -L/opt/apps/intel/13/composer_xe_2013.3.163/compiler/lib/intel64 -Wl,-rpath,/usr/lib/gcc/x86_64-redhat-linux/4.4.7 -L/usr/lib/gcc/x86_64-redhat-linux/4.4.7 -lmpichf90 -Wl,-rpath,/opt/apps/intel/13/composer_xe_2013.2.146/compiler/lib/intel64 -lifport -lifcore -lm -lm -lmpichcxx -ldl -lmpich -lopa -lmpl -libmad -lrdmacm -libumad -libverbs -lrt -llimic2 -lpthread -limf -lsvml -lirng -lipgo -ldecimal -lcilkrts -lstdc++ -lgcc_s -lirc -lirc_s -ldl 
-----------------------------------------

 
TACC: Shutdown complete. Exiting.
