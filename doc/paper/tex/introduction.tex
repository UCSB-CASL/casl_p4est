%!TEX root = draft.tex
\section{Introduction}\label{sec:introduction}
The level-set method, originally proposed by Sethian and Osher \cite{Osher;Sethian:88:Fronts-Propagating-w}, is a popular and powerful framework for tracking arbitrary interfaces that undergo complicated topological changes. As a result, the level-set method has been used to a wide range of applications such as multiphase flows, image segmentation, and computer graphics \cite{Osher;Fedkiw:02:Level-Set-Methods-an,Sethian:99:Level-set-methods-an}. An important feature of this method is that the location of the interface is defined implicitly on an underlying grid. This convenience, however, comes at a price. First, compared to an explicit method, e.g.\ front tracking \cite{Juric:96:A-Front-Tracking-Met, Tryggvason;Bunner;Esmaeeli;etal:01:A-Front-Tracking-Met}, the level-set method is typically less accurate and mass conservation could be a problem, although progress has been made in resolving this issue \cite{Enright;Fedkiw;Ferziger;etal:02:A-Hybrid-Particle-Le}. Second, the level-set function has to be defined in a one dimension higher space than that of the interface. If only the location of the interface is needed, the added dimension greatly increases the overall computational cost for uniform grids. One way to avoid this problem is by computing the level-set only close to the interface, e.g.\ as in the narrow-band level-set method \cite{Adalsteinsson;Sethian:95:A-Fast-Level-Set-Met} or, more recently, by using a hash table to restrict both computation and storage requirements \cite{Brun;Guittet;Gibou:12:A-local-level-set-me}.

Another approach that can address both problems is the use of local grid refinement. In \cite{Strain:99:Tree-Methods-for-Mov} the idea of using tree-based grids for level-set calculations was first introduced and later extended in \cite{Popinet:03:Gerris:-A-Tree-Based, Losasso;Gibou;Fedkiw:04:Simulating-Water-and} for fluid simulations. More recently, authors in \cite{Min;Gibou:07:A-second-order-accur} proposed second-order accurate level-set methods on Quadtree (two spatial dimensions) and Octree (three spatial dimensions) grids. The use of adaptive tree-base grids in the context of the level-set method is quite advantageous because (i) it gives fine-grain control over errors, which typically occur close to the interface and (ii) it can effectively reduce the dimensionality of the problem by focusing most of the grid cells close to the interface. Fortunately, constructing the tree is quite simple in the presence of an interface that naturally defines an ideal metric for refinement. However, even though the use of adaptive grids can dramatically reduce the computational cost, performing high-resolution three dimensional calculations of complex interfacial problems, e.g.\ crystal growth in binary alloys \cite{Theillard;Gibou;Pollock:14:A-Sharp-Computationa}, could be prohibitively expensive or even impossible on a serial machine.
In this paper we extend the level-set technology on Quad-/Octrees by proposing
parallel algorithms for distributed memory machines using a domain
decomposition technique.

One of the main challenges in parallelizing algorithms on adaptive grids is
handling the grid itself.
One option is to replicate the entire grid on each process and to employ serial
ordering techniques, as originally implemented by the \texttt{deal.II} library
\cite{Bangerth;Hartmann;Kanschat:07:deal.II----a-General}, or serial
graph partitioners such as METIS \cite{KarypisKumar95}.
%
% off-the-shelf graph partitioners, e.g.\ ParMetis
% \cite{Karypis;Kumar:98:A-parallel-algorithm} or Zoltan
% \cite{Boman;Catalyurek;Chevalier;etal:12:The-Zoltan-and-Isorr}, for load
% balancing and domain decomposition.
% For instance, this was the approach originally taken by the \texttt{deal.II}
% library \cite{Bangerth;Hartmann;Kanschat:07:deal.II----a-General}.
%
This approach, however, is only scalable to a few hundred processes at best and
is limited by the size of the grid itself that can fit in memory.
Even though parallel general-purpose partitioners have since been popularized
\cite{Karypis;Kumar:98:A-parallel-algorithm,
Boman;Catalyurek;Chevalier;etal:12:The-Zoltan-and-Isorr} and
the scalability of partitioning algorithms for unstructured grids
has been improved (see e.g.\ \cite{SahniZhouShephardEtAl09}),
% the use of a general-purpose graph partitioner
their use
adds extra overhead that can limit the overall scalability.
Interestingly, tree-based grids have a nice spatial ordering that naturally
leads to the concept of space-filling curves (SFCs) and can be efficiently
exploited for parallel load balancing
\cite{Aluru;Sevilgen:97:Parallel-domain-deco, GriebelZumbusch99,
      Campbell;Devine;Flaherty;etal:03:Dynamic-octree-load-}.

The idea of using SFCs for parallel partitioning of Quad-/Octrees is not new in itself and has been used by many researchers. For instance, \texttt{Octor} \cite{Tu;OHallaron;Ghattas:05:Scalable-parallel-oc} uses a Morton curve (also known as Z-curve) for traversing the leaves of an Octree for indexing and load balancing and has been scaled up to 62,000 cores \cite{Burstedde;Ghattas;Gurnis;etal:08:Scalable-adaptive-ma}.
\texttt{Dendro} \cite{Sampath;Adavani;Sundar;etal:08:Dendro:-parallel-alg} is
an example of a so-called linear Octree code in which new algorithms are
introduced for parallel partitioning and the development of a parallel
geometric multigrid that has been scaled up to about 32,000 cores
\cite{Sampath;Biros:10:A-parallel-geometric}.
More recently, authors in
\cite{Burstedde;Wilcox;Ghattas:11:p4est:-Scalable-Algo} extended these ideas by
optionally allowing for a collection, or a ``forest'', of connected Octrees,
% that are connected through a common, potentially unstructured, hexahedral grid.
which is partitioned in parallel using a global Morton curve.
%
% \textcolor{red}{How about adding the p4est comments here ?}
%
% An implementation of these algorithms is publicly available
%
% provides a simple API for handling the grid.
The \texttt{p4est} library \cite{p4est-github} provides a publicly available
implementation of these algorithms that is equally efficient for a single tree
as well as multiple trees and has been shown to scale to more than
% 200,000 cores,
450,000 CPU cores \cite{IsaacBursteddeWilcoxEtAl15}.
In fact, the algorithms presented in this paper are implemented on top of
the \texttt{p4est} API.
Due to the need for multiple adaptation and partitioning operations in each
time step, the semi-Lagrangian method we describe below presents a stringent
test of the algorithms and implementation both in terms of scalability and
absolute run time.
% using a single octree to represent the unit cube.
% In fact, the algorithms presented in this paper are implemented on top of the
% \texttt{p4est} library \cite{p4est-github} that is publicly available and
% provides a simple API for handling the grid.
%
% and we do not discuss any algorithm that is already covered in
% \cite{Burstedde;Wilcox;Ghattas:11:p4est:-Scalable-Algo}.

Parallel level-set algorithms can be categorized into two groups: parallel advection algorithms and parallel reinitialization algorithms. Eulerian advection schemes can easily be parallelized but unfortunately are limited by the CFL condition, which could be very restrictive for adaptive grids. Semi-Lagrangian methods combine the unconditional stability of Lagrangian methods and the ease of use of Eulerian grids and have been successfully used for advecting the level-set function on tree-based grids \cite{Losasso;Gibou;Fedkiw:04:Simulating-Water-and, Losasso;Fedkiw;Osher:06:Spatially-Adaptive-T, Min;Gibou:07:A-second-order-accur}. However, parallelizing the semi-Lagrangian algorithm in a domain decomposition context is not an easy task.
The reason for this is twofold.
First, depending on the CFL number, the departure points may end up outside the
ghost region and in remote processes that are potentially far away.
This requires a very dynamic and nonuniform communication pattern that is
challenging to implement.
For an adaptive grid, the situation is even more complex due to the asymmetric
nature of the communication pattern (cf.\ section \ref{sec:parallel
algorithms}).
Second, load balancing could be an issue for large CFL numbers and nonuniform
velocity fields, due to clustering of departure points, which can thus
considerably restrict the scalability of the algorithm. Both of these problems,
of course, could be avoided by choosing $\text{CFL} \le 1$ but that would
defeat the purpose of using the semi-Lagrangian algorithm in the first place.

Nonetheless, several parallel semi-Lagrangian algorithms have been proposed.
A simple domain decomposition technique was used in
\cite{Thomas;Cote:95:Massively-parallel-s} where the width of the ghost layer
is fixed based on the maximum CFL number to ensure that all departure points
are covered by the ghost layer.
Good scalings were reported for small CFL numbers ($\text{CFL} \le 2$).
However, for large CFL numbers, this leads to a large volume of communication that can limit the scalability. In \cite{Drake;Foster;Michalakes;etal:95:Design-and-performan} the authors propose a more sophisticated domain decomposition approach which uses a ``dynamic ghost layer''. Here the width of the ghost layer is dynamically determined at runtime based on information from previous time steps. Unfortunately, this approach also suffers from excessive communication overhead at large numbers of processes. More recently, the authors in \cite{White-III;Dongarra:11:High-performance-hig} used a domain decomposition strategy on a cubed sphere but with a single layer of ghost nodes. Interpolation on remote processes is then handled by sending query points to the corresponding process and asking for the interpolated result. This approach seems to provide good scalability for transporting a single tracer up to about 1000 cores for $\text{CFL} \sim 10$. At higher CFL numbers, the method begins to loose scalability due to an increase in communication volume. Finally, note that although we are mainly interested in parallel semi-Lagrangian methods, one could resort to finite difference or finite element discretization methods if small CFL numbers are acceptable. Indeed several algorithms of this type have been proposed with applications to modeling dendritic crystal growth \cite{Wang;Chang;Kale;etal:06:Parallelization-of-a}, multiphase flows \cite{Sussman:05:A-parallelized-adapt, Fortmeier;Bucker:11:A-parallel-strategy-, Rodriguez;Sahni;Lahey-Jr;etal:13:A-parallel-adaptive-}, and atomization process \cite{Herrmann:10:A-parallel-Eulerian-}.
%, and image segmentation on GPUs \cite{Lefohn;Cates;Whitaker:03:Interactive-GPU-base,Cates;Lefohn;Whitaker:04:GIST:-an-interactive,Roberts;Packer;Sousa;etal:10:A-work-efficient-GPU}.

In many applications, it is desirable that the level-set function has the signed-distance property, i.e., $|\nabla \phi| = 1$. Generally, there are two approaches to enforce this property, either by solving the pseudo-time transient reinitialization equation \cite{Sussman;Smereka;Osher:94:A-Level-Set-Approach, Osher;Fedkiw:01:Level-Set-Methods:-A}
\ben
\phi_\tau + S(\phi_0)\left(|\nabla \phi| - 1\right) = 0,
\een
or by solving the Eikonal equation
\ben
F(x)|\nabla\phi| = 1
\een 
with constant speed function $F(x) \equiv 1$. The transient reinitialization equation can be solved using explicit finite differences and thus can easily be parallelized in a domain decomposition approach. Moreover, only a few iterations may be needed if the signed-distance property is only required close to the interface \cite{Min;Gibou:07:A-second-order-accur}. This is the approach we have chosen in this paper. However, if the signed-distance property is required in the entire domain, solving the Eikonal equation is more computationally efficient. Unfortunately, the most popular algorithm for solving the Eikonal equation, i.e.\ the Fast Marching Method \cite{Sethian:96:A-Fast-Marching-Leve,Sethian:99:Level-set-methods-an}, is inherently sequential due to causal relationship between grid points and cannot be easily parallelized.
The Fast Sweeping Method (FSM) \cite{Zhao:05:A-fast-sweeping-meth} is an
alternative for solving the Eikonal equation iteratively.
The FSM can be more computationally efficient for simple choices of speed
function, e.g.\ as in this context, and for simple interfaces.
Moreover, FSM has more potential for parallelization compared to the FMM.

One of the earliest attempt in parallelizing the FMM is reported in \cite{Herrmann:03:A-domain-decompositi} where a domain decomposition algorithm was introduced. Unlike the serial FMM, however, parallel FMM potentially requires multiple iterations or ``rollback operations'' to enforce causality across processes. Similar ideas are described in detail in \cite{Tugurlan:08:Fast-marching-method}. It should be noted that the number of iterations needed for the parallel FMM to converge greatly depends on the complexity of the interface and on the parallel partitioning and, in general, fewer iterations are required if the domains are aligned with the normals to the interface. Due to the nature of the Eikonal equation, shared memory machines might be a better environment for parallelization. For instance, in \cite{Breus;Cristiani;Gwosdek;etal:11:An-adaptive-domain-d} the authors use an ``adaptive'' technique where individual threads implicitly define a domain decomposition at runtime. Unfortunately, this approach does not seem to be more effective than a simple static decomposition. In \cite{Zhao:07:Parallel-implementat} a parallel FSM method was presented for the first time, which suffered from a plateau in the speedup. A scalable FSM was more recently proposed in \cite{Detrixhe;Gibou;Min:13:A-parallel-fast-swee}, where the Cuthill-McKee numbering was utilized to improve scalability.  A two-scale, hybrid FMM-FSM was presented in \cite{Chacon;Vladimirsky:13:A-parallel-Heap-Cell} which, albeit being more complicated to implement, promises even better scalability. Finally, a parallel Fast Iterative Method (FIM) was proposed in \cite{Jeong;Whitaker:08:A-fast-iterative-met}. The FIM is similar to FMM in that it also maintains a list of ``active nodes''. However, unlike FMM, FIM avoids sorting the list and allows for concurrent updating of all nodes in an iterative fashion. In this article we choose the pseudo-time transient formulation for two reasons: 1) it is considerably easier to parallelize on Quadtrees and Octrees and 2) we are merely interested in the signed-distance property close to the interface, which only requires a few iterations.

This article is organized as follows: In section \ref{sec:levelset method}, we briefly review the sequential algorithms and discretization methods for the level-set equation on adaptive tree-based grids. These ideas are then extended in section \ref{sec:parallel algorithms} to parallel environments using a domain decomposition method. In section \ref{sec:scaling}, we provide several examples that illustrate the scalability of our algorithms. Finally, we close by providing an application of our method by considering the simulation of the solidification process by solving a Stefan problem in section \ref{sec:application}.
